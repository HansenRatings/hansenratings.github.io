library(RSelenium)
library(XML)
library(dplyr)
library(purrr)
library(rvest)
library(stringr)
library(readr)
# shell('docker run -d -p 4445:4444 selenium/standalone-chrome')
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4445L, browserName = "chrome")
remDr$open()
remDr$open()
remDr$navigate("https://d3football.com/conf/NESCAC/2022/schedule")
remDr$screenshot(display = TRUE)
remDr$getScreenshot()
install.packages("rselenium")
remDr$close()
remDr$open()
remDr$navigate("https://d3football.com/conf/NESCAC/2022/schedule")
library(tidyr)
library(purrr)
library(readr)
library(dplyr)
library(htmltools)
library(stringr)
library(reactable)
library(reactablefmtr)
library(showtext)
library(curl)
font_add_google("Raleway", "raleway")
showtext_auto()
setwd("C:/Users/logan/OneDrive/R/Hansen Ratings")
date_of_update <- "Updated through games as of 11/12/2023"
game_week <- "Round 1"
# Render a bar chart in the background of the cell
bar_style <- function(width = 1, fill = "#323e4f", height = "75%",
align = c("left", "right"), color = NULL) {
align <- match.arg(align)
if (align == "left") {
position <- paste0(width * 100, "%")
image <- sprintf("linear-gradient(90deg, %1$s %2$s, transparent %2$s)", fill, position)
} else {
position <- paste0(100 - width * 100, "%")
image <- sprintf("linear-gradient(90deg, transparent %1$s, %2$s %1$s)", position, fill)
}
list(
backgroundImage = image,
backgroundSize = paste("100%", height),
backgroundRepeat = "no-repeat",
backgroundPosition = "center",
color = color
)
}
with_tooltip <- function(value, tooltip) {
tags$abbr(style = "text-decoration: underline; text-decoration-style: dotted; cursor: help",
title = tooltip, value)
}
blue_to_orange = c("#323e4f","#ffffff","#ed7d31")
white_to_orange = c("#ffffff","#ed7d31")
blue_to_white = c("#323e4f","#ffffff")
# Season_Sim <- read_csv("2023 Week 11 Season Simulation.csv")
Playoff_Sim <- read_csv("2023 Playoff Simulation.csv")
Game_Proj <- read_csv("2023 Round 1 Games.csv")
# These next two lines are temporary until you finish automating the resume/power ratings
Power_Ratings <- read_csv("2023 Round 1 Power Ratings.csv")
Resume_Rankings <- read_csv("2023 Round 1 Resume Rankings.csv")
Schedules <- read_csv("2023 Schedule Strength.csv")
setwd("C:/Users/logan/OneDrive/Documents/hansenratings.github.io")
Resume_Rankings %>% reactable(pagination = FALSE,
style = list(fontFamily = "Raleway"),
defaultSortOrder = "desc",
highlight = TRUE,
rownames = TRUE,
showSortIcon = FALSE,
defaultColDef = colDef(
style = JS("function(rowInfo, column, state) {
// Highlight sorted columns
for (let i = 0; i < state.sorted.length; i++) {
if (state.sorted[i].id === column.id) {
return { background: 'rgba(0, 0, 0, 0.05)' }
}
}
}")
),
columns = list(
.rownames = colDef(show = FALSE),
Rank = colDef(
minWidth = 60,
header = with_tooltip(
"Rank",
"Teams are ranked according to a mixture of all of the metrics on this page - 'who did you beat, and how well did you play?'"),
sticky = "left"),
Prev = colDef(
minWidth = 60),
Team = colDef(
minWidth = 200,
filterable = TRUE,
sticky = "left"),
Conf = colDef(
minWidth = 95,
filterable = TRUE),
Region = colDef(
minWidth = 70,
filterable = TRUE),
'MOV+' = colDef(
minWidth = 60,
header = with_tooltip(
"MOV+",
"Margin of victory 'plus', how much more or less you've outscored your opponents than a typical Top 25 team would be expected to"),
format = colFormat(digits = 1),
style = color_scales(Resume_Rankings,
colors = blue_to_orange)),
SOR = colDef(
minWidth = 70,
header = with_tooltip(
"SOR",
"Strength of record, represented as the likelihood a typical Top 25 team would have a W-L record at least as good against the same opponents"),
format = colFormat(percent = TRUE,
digits = 1),
style = color_scales(Resume_Rankings,
colors = blue_to_white)),
'E+' = colDef(
minWidth = 60,
header = with_tooltip(
"E+",
"Elite games, the percentage of games where the team performed at an elite level or better (+36 points per game relative to an average team)"),
format = colFormat(percent = TRUE,
digits = 0),
style = color_scales(Resume_Rankings,
colors = white_to_orange)),
'G+' = colDef(
minWidth = 60,
header = with_tooltip(
"G+",
"Good games, the percentage of games where the team performed at a good level or better (+18 points per game relative to an average team)"),
format = colFormat(percent = TRUE,
digits = 0),
style = color_scales(Resume_Rankings,
colors = white_to_orange)),
'A+' = colDef(
minWidth = 60,
header = with_tooltip(
"A+",
"Average games, the percentage of games where the team performed at an average level or better"),
format = colFormat(percent = TRUE,
digits = 0),
style = color_scales(Resume_Rankings,
colors = white_to_orange)),
BA = colDef(
minWidth = 60,
header = with_tooltip(
"BA",
"Below average games, the percentage of games where the team performed at a below average level"),
format = colFormat(percent = TRUE,
digits = 0),
style = color_scales(Resume_Rankings,
colors = blue_to_white)),
EAW = colDef(
minWidth = 60,
header = with_tooltip(
"EAW",
"Elite adjusted wins, how many more/fewer games the team has won than an elite team (+36 points per game relative to an average team) would be expected to win"),
format = colFormat(digits = 1),
style = color_scales(Resume_Rankings,
colors = blue_to_orange)),
GAW = colDef(
minWidth = 60,
header = with_tooltip(
"GAW",
"Good adjusted wins, how many more/fewer games the team has won than a good team (+18 points per game relative to an average team) would be expected to win"),
format = colFormat(digits = 1),
style = color_scales(Resume_Rankings,
colors = blue_to_orange)),
AAW = colDef(
minWidth = 60,
header = with_tooltip(
"AAW",
"Average adjusted wins, how many more/fewer games the team has won than an average team would be expected to win"),
format = colFormat(digits = 1),
style = color_scales(Resume_Rankings,
colors = blue_to_orange)),
Wins = colDef(
minWidth = 60,
header = with_tooltip(
"Wins",
"Season-to-date wins against all opponents")),
Losses = colDef(
minWidth = 70,
header = with_tooltip(
"Losses",
"Season-to-date losses against all opponents")),
'DIII W' = colDef(
minWidth = 65,
header = with_tooltip(
"DIII W",
"Season-to-date wins against Division III opponents")),
'DIII L' = colDef(
minWidth = 60,
header = with_tooltip(
"DIII L",
"Season-to-date losses against Division III opponents")),
'Conf W' = colDef(
minWidth = 75,
header = with_tooltip(
"Conf W",
"Season-to-date wins against conference opponents (may not align with official conference standings, if the team plays some conference members as a 'non-conference' opponent)")),
'Conf L' = colDef(
minWidth = 70,
header = with_tooltip(
"Conf L",
"Season-to-date losses against conference opponents (may not align with official conference standings, if the team plays some conference members as a 'non-conference' opponent)"))
)) %>%
add_title("2023 DIII Football Resume Rankings") %>%
add_subtitle(date_of_update,
font_size = 10, font_weight = "normal", font_style = "italic") %>%
reactablefmtr::google_font(font_family = "Raleway") %>%
save_reactable_test("2023 Resume Rankings.html")
library(rvest)
# URL of the website
url <- "http://stats.ncaa.org/season_divisions/18190/livestream_scoreboards?utf8=%E2%9C%93&season_division_id=&game_date=11%2F11%2F2023&conference_id=0&tournament_id=&commit=Submit"
# Read the HTML content of the webpage
page <- read_html(url)
page
# Extract the table containing contest IDs
table_data <- html_table(page, fill = TRUE)[[1]]
table_data
View(table_data)
View(page)
page[[3]]
page[[1]]
page[[2]]
page[[3]]
page[1]
page[2]
page
page[3]
page$doc
page$node
page<html>
page<html()
html(page)
page[3]
page$node
page$doc
head(page)
page
# Extract the table rows with id attribute
rows <- html_nodes(page, "tr[id]")
# Extract the contest IDs from the rows
contest_ids <- html_attr(rows, "id")
# Display unique contest IDs
unique_contest_ids <- unique(contest_ids)
print(unique_contest_ids)
# Remove "contest_" from each item
contest_ids <- sub("contest_", "", contest_ids)
# Display unique contest IDs
unique_contest_ids <- unique(contest_ids)
print(unique_contest_ids)
# URL of the website
url <- "http://stats.ncaa.org/season_divisions/18190/livestream_scoreboards?utf8=%E2%9C%93&season_division_id=&game_date=11%2F11%2F2023&conference_id=0&tournament_id=&commit=Submit"
# Read the HTML content of the webpage
page <- read_html(url)
# Extract the table rows with id attribute
rows <- html_nodes(page, "tr[id]")
# Extract the contest IDs from the rows
contest_ids <- html_attr(rows, "id")
# Remove "contest_" from each item
contest_ids <- sub("contest_", "", contest_ids)
# Create a new vector with the desired format
contest_urls <- paste("https://stats.ncaa.org/contests/", contest_ids, "/play_by_play", sep = "")
# Display the resulting URLs
print(contest_urls)
# Define a vector of game dates
game_dates <- c(
"8/31/2023", "9/1/2023", "9/2/2023", "9/7/2023", "9/8/2023", "9/9/2023",
"9/15/2023", "9/16/2023", "9/21/2023", "9/23/2023", "9/24/2023",
"9/29/2023", "9/30/2023", "10/6/2023", "10/7/2023", "10/12/2023",
"10/14/2023", "10/20/2023", "10/21/2023", "10/28/2023", "11/3/2023",
"11/4/2023", "11/10/2023", "11/11/2023"
)
# Function to scrape and create URLs for a given game date
get_contest_urls <- function(game_date) {
# URL of the website for the specific game date
url <- paste("http://stats.ncaa.org/season_divisions/18190/livestream_scoreboards?utf8=%E2%9C%93&season_division_id=&game_date=",
gsub("/", "%2F", game_date), "&conference_id=0&tournament_id=&commit=Submit", sep = "")
# Read the HTML content of the webpage
page <- read_html(url)
# Extract the table rows with id attribute
rows <- html_nodes(page, "tr[id]")
# Extract the contest IDs from the rows
contest_ids <- html_attr(rows, "id")
# Remove "contest_" from each item
contest_ids <- sub("contest_", "", contest_ids)
# Create a new vector with the desired format
contest_urls <- paste("https://stats.ncaa.org/contests/", contest_ids, "/play_by_play", sep = "")
# Return the resulting URLs
return(contest_urls)
}
# Apply the function to each game date
all_contest_urls <- lapply(game_dates, get_contest_urls)
# Display the resulting URLs for each game date
print(all_contest_urls)
all_contest_urls[[1]][1]
read_html(all_contest_urls[[1]][1])
# Select the first URL from the list of all contest URLs
first_url <- all_contest_urls[[1]][1]
# Read the HTML content of the webpage
page <- read_html(first_url)
# Specify the XPath expression
xpath_expression <- '//*[@id="ui-accordion-1-panel-0"]'
# Extract data using the XPath expression
extracted_data <- html_nodes(page, xpath = xpath_expression) %>% html_text()
# Display the extracted data
print(extracted_data)
# Specify the XPath expression
xpath_expression <- '//*[@id="ui-accordion-1-panel-0"]/div[1]'
# Extract data using the XPath expression
extracted_data <- html_nodes(page, xpath = xpath_expression) %>% html_text()
# Display the extracted data
print(extracted_data)
# Specify the XPath expression
xpath_expression <- '//*[@id="ui-accordion-1-panel-0"]/div[1]/span[1]/text()'
# Extract data using the XPath expression
extracted_data <- html_nodes(page, xpath = xpath_expression) %>% html_text()
# Display the extracted data
print(extracted_data)
# Select the first URL from the list of all contest URLs
first_url <- all_contest_urls[[1]][1]
# Read the HTML content of the webpage
page <- read_html(first_url)
# Specify the XPath expression
xpath_expression <- '//*[@id="ui-accordion-1-panel-0"]/div[1]/span[1]/text()'
# Extract data using the XPath expression
extracted_data <- html_nodes(page, xpath = xpath_expression) %>% html_text()
# Display the extracted data
print(extracted_data)
# Extract data using the XPath expression
extracted_data <- html_nodes(page, xpath = xpath_expression)
# Display the extracted data
print(extracted_data)
library(RSelenium)
# Select the first URL from the list of all contest URLs
first_url <- all_contest_urls[[1]][1]
# Start a Selenium server
# You might need to download the appropriate browser driver
# and provide the path to the executable in the command below
# For example, for Chrome:
# system("java -Dwebdriver.chrome.driver=/path/to/chromedriver -jar selenium-server-standalone.jar")
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "chrome")
remDr$open()
# Start a Selenium server
# You might need to download the appropriate browser driver
# and provide the path to the executable in the command below
# For example, for Chrome:
system("java -Dwebdriver.chrome.driver=/path/to/chromedriver -jar selenium-server-standalone.jar")
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "chrome")
remDr$open()
# Start a Selenium server
shell('docker run -d -p 4445:4444 selenium/standalone-chrome')
